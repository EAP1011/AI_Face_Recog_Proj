{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIprojFaceRecog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNMwXOr3CWjm"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcKnoaQhJuji"
      },
      "source": [
        "num_classes = 7\n",
        "img_rows,img_cols = 48,48\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrEh8x4NmaeQ"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExROJxPTqwIK"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "\t\t\t\t\trescale=1./255,\n",
        "\t\t\t\t\trotation_range=30,\n",
        "\t\t\t\t\tshear_range=0.3,\n",
        "\t\t\t\t\tzoom_range=0.3,\n",
        "\t\t\t\t\twidth_shift_range=0.4,\n",
        "\t\t\t\t\theight_shift_range=0.4,\n",
        "\t\t\t\t\thorizontal_flip=True,\n",
        "\t\t\t\t\tfill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGXQyyveq1T5"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snNSfOIuq3rm",
        "outputId": "0d702453-ac52-4191-dddc-63f9c23e7eb2"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "\t\t\t\t\ttrain_data_dir,\n",
        "\t\t\t\t\tcolor_mode='grayscale',\n",
        "\t\t\t\t\ttarget_size=(img_rows,img_cols),\n",
        "\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\tclass_mode='categorical',\n",
        "\t\t\t\t\tshuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28826 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oV-UCEAq5qX",
        "outputId": "089d77ea-d9eb-43e8-cbc6-5d853c754970"
      },
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\t\t\t\t\t\t\tvalidation_data_dir,\n",
        "\t\t\t\t\t\t\tcolor_mode='grayscale',\n",
        "\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\n",
        "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t\t\tclass_mode='categorical',\n",
        "\t\t\t\t\t\t\tshuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7066 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQUodwlrrHlC"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do-tgez8rNQI"
      },
      "source": [
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8nU5nTSrQSw"
      },
      "source": [
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDe9IV3drSl9"
      },
      "source": [
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-J-7kN8rVdV"
      },
      "source": [
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5LtOXj-rYuF"
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0hd8uh_rbaL"
      },
      "source": [
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vE3rgcErdRN"
      },
      "source": [
        "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym3L9me8rfE0",
        "outputId": "5d04a0b4-421a-4d1e-926a-537dae484dde"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                147520    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 455       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 1,328,167\n",
            "Trainable params: 1,325,991\n",
            "Non-trainable params: 2,176\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzNrRPg3rhDr"
      },
      "source": [
        "from keras.optimizers import RMSprop,SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1S_-1Ggrlnt"
      },
      "source": [
        "checkpoint = ModelCheckpoint('Emotion_little_vgg.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0-O-Akyst7o"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tT6K9crsxI7"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2OtDgmoszBm"
      },
      "source": [
        "callbacks = [earlystop,checkpoint,reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RZKmLkUs1Tj"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZwdTtrjs3NU"
      },
      "source": [
        "nb_train_samples = 24176\n",
        "nb_validation_samples = 3006\n",
        "epochs=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGXXuuHes498",
        "outputId": "8cf68855-0e1c-4e24-ce6b-ace2b7295754"
      },
      "source": [
        "history=model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples//batch_size,\n",
        "                epochs=epochs,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=nb_validation_samples//batch_size)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "755/755 [==============================] - 2625s 3s/step - loss: 2.1590 - accuracy: 0.1878 - val_loss: 1.7807 - val_accuracy: 0.2597\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.78066, saving model to Emotion_little_vgg.h5\n",
            "Epoch 2/8\n",
            "755/755 [==============================] - 969s 1s/step - loss: 1.8373 - accuracy: 0.2271 - val_loss: 1.7736 - val_accuracy: 0.2651\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.78066 to 1.77356, saving model to Emotion_little_vgg.h5\n",
            "Epoch 3/8\n",
            "755/755 [==============================] - 494s 654ms/step - loss: 1.8009 - accuracy: 0.2476 - val_loss: 1.7538 - val_accuracy: 0.2849\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.77356 to 1.75385, saving model to Emotion_little_vgg.h5\n",
            "Epoch 4/8\n",
            "755/755 [==============================] - 269s 356ms/step - loss: 1.7872 - accuracy: 0.2532 - val_loss: 1.7470 - val_accuracy: 0.2708\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.75385 to 1.74704, saving model to Emotion_little_vgg.h5\n",
            "Epoch 5/8\n",
            "755/755 [==============================] - 164s 217ms/step - loss: 1.7576 - accuracy: 0.2718 - val_loss: 1.6719 - val_accuracy: 0.3330\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.74704 to 1.67185, saving model to Emotion_little_vgg.h5\n",
            "Epoch 6/8\n",
            "755/755 [==============================] - 126s 166ms/step - loss: 1.7081 - accuracy: 0.3019 - val_loss: 1.5390 - val_accuracy: 0.3810\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.67185 to 1.53905, saving model to Emotion_little_vgg.h5\n",
            "Epoch 7/8\n",
            "755/755 [==============================] - 97s 128ms/step - loss: 1.6293 - accuracy: 0.3531 - val_loss: 1.5013 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.53905 to 1.50128, saving model to Emotion_little_vgg.h5\n",
            "Epoch 8/8\n",
            "755/755 [==============================] - 89s 118ms/step - loss: 1.5622 - accuracy: 0.3905 - val_loss: 1.3871 - val_accuracy: 0.4560\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.50128 to 1.38707, saving model to Emotion_little_vgg.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLIcT9pRTHF9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtQtw87TJ2S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}